# Careti Agent Benchmark

[English](README.en.md) | [한국어](README.ko.md) | [日本語](README.ja.md) | [中文](README.zh.md) | [Français](README.fr.md) | [Deutsch](README.de.md) | [Русский](README.ru.md)

---

**Система бенчмарков для измерения реальной производительности ИИ-агентов программирования**

## Результаты

**[Посмотреть результаты бенчмарков](https://careti.ai/ru/benchmark)**

## Почему этот бенчмарк?

### Ограничения существующих бенчмарков

| Бенчмарк | Ограничение |
|----------|-------------|
| **HumanEval** | Измеряет только генерацию одной функции, оторван от реальной разработки |
| **SWE-bench** | Измеряет решение задач GitHub, но не отражает использование инструментов агентом |
| **MBPP** | Простые задачи Python, нет поддержки сложных многофайловых задач |

**Ключевая проблема**: Существующие бенчмарки измеряют только "способность генерации кода". Но реальные ИИ-агенты программирования (Cline, Cursor, Careti и др.) **используют инструменты, видят ошибки и исправляют их, делают несколько попыток**.

### Что измеряет этот бенчмарк

```
Традиционный: Задача → Модель → Код → Оценка (1 раз)
Careti:       Задача → Агент → Код → Тест → [Обратная связь об ошибке] → Повтор → ... → Финальный результат
```

## Последние результаты (Hard Suite 100)

| Ранг | Модель | 1-я попытка | Итоговый | Ср. попытки | Стоимость |
|------|--------|-------------|----------|-------------|-----------|
| #1 | Gemini 2.5 Flash | 62-67% | **98%** | 1.36-1.44 | $0.09-0.13 |
| #2 | GLM-4.7 | 89-92% | **97-98%** | 1.11-1.15 | $0.18 |
| #3 | Gemini 3 Pro (Preview) | 66-67% | **92-93%** | 1.53-1.57 | $0.60 |
| #4 | Solar Pro2 | 61-64% | **81-86%** | 1.82-1.87 | $0.75-0.87 |
| #5 | Solar Pro3 | 70% | **75%** | 1.71 | $1.35 |
| #6 | HyperCLOVA X | 1-2% | **1-2%** | 3.03-3.06 | $0.22-0.31 |

## Ключевые метрики

| Метрика | Значение | Почему важно? |
|---------|----------|---------------|
| **Успех 1-й попытки** | Доля успеха с первой попытки | "Интуиция" агента - определяет время ожидания пользователя |
| **Итоговый успех** | Доля успеха включая повторы | "Способность решать проблемы" агента |
| **Среднее попыток** | Среднее количество попыток на задачу | Показатель эффективности |
| **Стоимость** | Общая стоимость API | Экономическая целесообразность |

## Условия завершения

| Условие | Описание |
|---------|----------|
| `success` | Тест пройден |
| `max_attempts` | Достигнуто макс. попыток (5) |
| `timeout` | Превышен лимит времени (300с) |
| `oscillation` | Обнаружен паттерн A↔B осцилляции |
| `same_error` | Та же ошибка повторена 3 раза |

## Сырые данные

Директория `results/` содержит полные данные бенчмарков в формате JSON.

### Структура данных

```json
{
  "problem_id": "he000-has_close_elements",
  "model": "Gemini 2.5 Flash",
  "success": true,
  "attempts": 1,
  "first_attempt_success": true,
  "total_time_ms": 5348,
  "cost_usd": 0.00018,
  "input_tokens": 161,
  "output_tokens": 264,
  "prompt_mode": "careti",
  "termination_reason": "success",
  "attempt_history": [...]
}
```

### Поиск оригинальных задач

Задачи HumanEval можно получить из датасета Hugging Face:

```python
from datasets import load_dataset

ds = load_dataset("openai/openai_humaneval")
problem = ds["test"][0]  # he000 → задача 0
print(problem["prompt"])
```

**Hugging Face**: [openai/openai_humaneval](https://huggingface.co/datasets/openai/openai_humaneval)

## Лицензия

MIT

---

**Made by [Caretive](https://caretive.ai)** - Разработчики ИИ-агента программирования Careti
